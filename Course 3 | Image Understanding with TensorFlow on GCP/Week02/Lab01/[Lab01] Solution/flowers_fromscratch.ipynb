{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flowers Image Classification with TensorFlow on Cloud ML Engine\n",
    "\n",
    "This notebook demonstrates how to do image classification from scratch on a flowers dataset using the Estimator API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "PROJECT = 'qwiklabs-gcp-fbe436fd47a7ee13' # REPLACE WITH YOUR PROJECT ID\n",
    "BUCKET = 'qwiklabs-gcp-fbe436fd47a7ee13' # REPLACE WITH YOUR BUCKET NAME\n",
    "REGION = 'us-central1' # REPLACE WITH YOUR BUCKET REGION e.g. us-central1\n",
    "MODEL_TYPE = 'cnn'\n",
    "\n",
    "# do not change these\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['MODEL_TYPE'] = MODEL_TYPE\n",
    "os.environ['TFVERSION'] = '1.8'  # Tensorflow version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input functions to read JPEG images\n",
    "\n",
    "The key difference between this notebook and [the MNIST one](./mnist_models.ipynb) is in the input function.\n",
    "In the input function here, we are doing the following:\n",
    "* Reading JPEG images, rather than 2D integer arrays.\n",
    "* Reading in batches of batch_size images rather than slicing our in-memory structure to be batch_size images.\n",
    "* Resizing the images to the expected HEIGHT, WIDTH. Because this is a real-world dataset, the images are of different sizes. We need to preprocess the data to, at the very least, resize them to constant size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run as a Python module\n",
    "\n",
    "Since we want to run our code on Cloud ML Engine, we've packaged it as a python module.\n",
    "\n",
    "The `model.py` and `task.py` containing the model code is in <a href=\"flowersmodel\">flowersmodel</a>\n",
    "\n",
    "**Complete the TODOs in `model.py` before proceeding!**\n",
    "\n",
    "Once you've completed the TODOs, run it locally for a few steps to test the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py3env/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "INFO:tensorflow:TF_CONFIG environment variable: {'task': {}, 'environment': 'cloud', 'cluster': {}, 'job': {'args': ['--output_dir=/content/datalab/notebooks/training-data-analyst/courses/machine_learning/deepdive/08_image/labs/flowers_trained', '--train_steps=5', '--learning_rate=0.01', '--batch_size=2', '--model=cnn', '--augment', '--train_data_path=gs://cloud-ml-data/img/flower_photos/train_set.csv', '--eval_data_path=gs://cloud-ml-data/img/flower_photos/eval_set.csv'], 'job_name': 'flowersmodel.task'}}\n",
      "INFO:tensorflow:Using config: {'_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5b054c5c18>, '_train_distribute': None, '_task_id': 0, '_is_chief': True, '_task_type': 'worker', '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_keep_checkpoint_every_n_hours': 10000, '_save_checkpoints_steps': None, '_evaluation_master': '', '_num_ps_replicas': 0, '_save_summary_steps': 100, '_num_worker_replicas': 1, '_global_id_in_cluster': 0, '_log_step_count_steps': 100, '_service': None, '_save_checkpoints_secs': 300, '_model_dir': '/content/datalab/notebooks/training-data-analyst/courses/machine_learning/deepdive/08_image/labs/flowers_trained/', '_session_config': None, '_master': ''}\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 300 secs (eval_spec.throttle_secs) or training is finished.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /content/datalab/notebooks/training-data-analyst/courses/machine_learning/deepdive/08_image/labs/flowers_trained/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.8252339, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 5 into /content/datalab/notebooks/training-data-analyst/courses/machine_learning/deepdive/08_image/labs/flowers_trained/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 22.846235.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-04-04-02:32:08\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /content/datalab/notebooks/training-data-analyst/courses/machine_learning/deepdive/08_image/labs/flowers_trained/model.ckpt-5\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-04-04-02:34:02\n",
      "INFO:tensorflow:Saving dict for global step 5: accuracy = 0.14864865, global_step = 5, loss = 2.676723\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default', 'classes']\n",
      "INFO:tensorflow:Restoring parameters from /content/datalab/notebooks/training-data-analyst/courses/machine_learning/deepdive/08_image/labs/flowers_trained/model.ckpt-5\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b\"/content/datalab/notebooks/training-data-analyst/courses/machine_learning/deepdive/08_image/labs/flowers_trained/export/exporter/temp-b'1554345242'/saved_model.pb\"\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "rm -rf flowersmodel.tar.gz flowers_trained\n",
    "gcloud ml-engine local train \\\n",
    "   --module-name=flowersmodel.task \\\n",
    "   --package-path=${PWD}/flowersmodel \\\n",
    "   -- \\\n",
    "   --output_dir=${PWD}/flowers_trained \\\n",
    "   --train_steps=5 \\\n",
    "   --learning_rate=0.01 \\\n",
    "   --batch_size=2 \\\n",
    "   --model=$MODEL_TYPE \\\n",
    "   --augment \\\n",
    "   --train_data_path=gs://cloud-ml-data/img/flower_photos/train_set.csv \\\n",
    "   --eval_data_path=gs://cloud-ml-data/img/flower_photos/eval_set.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's do it on ML Engine. Note the --model parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://qwiklabs-gcp-fbe436fd47a7ee13/flowers/trained_cnn us-central1 flowers_cnn_190404_023455\n",
      "jobId: flowers_cnn_190404_023455\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing gs://qwiklabs-gcp-fbe436fd47a7ee13/flowers/trained_cnn/#1554345010009235...\n",
      "Removing gs://qwiklabs-gcp-fbe436fd47a7ee13/flowers/trained_cnn/checkpoint#1554345011412231...\n",
      "Removing gs://qwiklabs-gcp-fbe436fd47a7ee13/flowers/trained_cnn/eval/#1554345080463053...\n",
      "Removing gs://qwiklabs-gcp-fbe436fd47a7ee13/flowers/trained_cnn/eval/events.out.tfevents.1554345080.cmle-training-13249182261881939917#1554345081313923...\n",
      "Removing gs://qwiklabs-gcp-fbe436fd47a7ee13/flowers/trained_cnn/events.out.tfevents.1554344909.cmle-training-13249182261881939917#1554345090706402...\n",
      "Removing gs://qwiklabs-gcp-fbe436fd47a7ee13/flowers/trained_cnn/export/#1554345083953109...\n",
      "Removing gs://qwiklabs-gcp-fbe436fd47a7ee13/flowers/trained_cnn/export/exporter/#1554345084114422...\n",
      "/ [1/16 objects]   6% Done                                                      \r",
      "/ [2/16 objects]  12% Done                                                      \r",
      "Removing gs://qwiklabs-gcp-fbe436fd47a7ee13/flowers/trained_cnn/export/exporter/1554345081/#1554345089654890...\n",
      "/ [3/16 objects]  18% Done                                                      \r",
      "/ [4/16 objects]  25% Done                                                      \r",
      "/ [5/16 objects]  31% Done                                                      \r",
      "/ [6/16 objects]  37% Done                                                      \r",
      "Removing gs://qwiklabs-gcp-fbe436fd47a7ee13/flowers/trained_cnn/export/exporter/1554345081/saved_model.pb#1554345089804775...\n",
      "Removing gs://qwiklabs-gcp-fbe436fd47a7ee13/flowers/trained_cnn/export/exporter/1554345081/variables/#1554345089970536...\n",
      "Removing gs://qwiklabs-gcp-fbe436fd47a7ee13/flowers/trained_cnn/export/exporter/1554345081/variables/variables.data-00000-of-00001#1554345090142874...\n",
      "Removing gs://qwiklabs-gcp-fbe436fd47a7ee13/flowers/trained_cnn/export/exporter/1554345081/variables/variables.index#1554345090305860...\n",
      "/ [7/16 objects]  43% Done                                                      \r",
      "Removing gs://qwiklabs-gcp-fbe436fd47a7ee13/flowers/trained_cnn/graph.pbtxt#1554344913393699...\n",
      "/ [8/16 objects]  50% Done                                                      \r",
      "/ [9/16 objects]  56% Done                                                      \r",
      "/ [10/16 objects]  62% Done                                                     \r",
      "/ [11/16 objects]  68% Done                                                     \r",
      "/ [12/16 objects]  75% Done                                                     \r",
      "Removing gs://qwiklabs-gcp-fbe436fd47a7ee13/flowers/trained_cnn/model.ckpt-1.data-00000-of-00001#1554345010541731...\n",
      "Removing gs://qwiklabs-gcp-fbe436fd47a7ee13/flowers/trained_cnn/model.ckpt-1.index#1554345010783946...\n",
      "Removing gs://qwiklabs-gcp-fbe436fd47a7ee13/flowers/trained_cnn/model.ckpt-1.meta#1554345012306461...\n",
      "/ [13/16 objects]  81% Done                                                     \r",
      "/ [14/16 objects]  87% Done                                                     \r",
      "/ [15/16 objects]  93% Done                                                     \r",
      "/ [16/16 objects] 100% Done                                                     \r\n",
      "Operation completed over 16 objects.                                             \n",
      "Job [flowers_cnn_190404_023455] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs describe flowers_cnn_190404_023455\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs stream-logs flowers_cnn_190404_023455\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://${BUCKET}/flowers/trained_${MODEL_TYPE}\n",
    "JOBNAME=flowers_${MODEL_TYPE}_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "   --region=$REGION \\\n",
    "   --module-name=flowersmodel.task \\\n",
    "   --package-path=${PWD}/flowersmodel \\\n",
    "   --job-dir=$OUTDIR \\\n",
    "   --staging-bucket=gs://$BUCKET \\\n",
    "   --scale-tier=BASIC_GPU \\\n",
    "   --runtime-version=$TFVERSION \\\n",
    "   -- \\\n",
    "   --output_dir=$OUTDIR \\\n",
    "   --train_steps=1000 \\\n",
    "   --learning_rate=0.01 \\\n",
    "   --batch_size=40 \\\n",
    "   --model=$MODEL_TYPE \\\n",
    "   --augment \\\n",
    "   --batch_norm \\\n",
    "   --train_data_path=gs://cloud-ml-data/img/flower_photos/train_set.csv \\\n",
    "   --eval_data_path=gs://cloud-ml-data/img/flower_photos/eval_set.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring training with TensorBoard\n",
    "\n",
    "Use this cell to launch tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>TensorBoard was started successfully with pid 4890. Click <a href=\"/_proxy/47019/\" target=\"_blank\">here</a> to access it.</p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "4890"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.datalab.ml import TensorBoard\n",
    "TensorBoard().start('gs://{}/flowers/trained_{}'.format(BUCKET, MODEL_TYPE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped TensorBoard with pid 4803\n",
      "Stopped TensorBoard with pid 4890\n"
     ]
    }
   ],
   "source": [
    "for pid in TensorBoard.list()['pid']:\n",
    "  TensorBoard().stop(pid)\n",
    "  print('Stopped TensorBoard with pid {}'.format(pid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are my results:\n",
    "\n",
    "Model | Accuracy | Time taken | Run time parameters\n",
    "--- | :---: | ---\n",
    "cnn with batch-norm | 0.582 | 47 min | 1000 steps, LR=0.01, Batch=40\n",
    "as above, plus augment | 0.615 | 3 hr | 5000 steps, LR=0.01, Batch=40\n",
    "\n",
    "What was your accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying and predicting with model\n",
    "\n",
    "Deploy the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting and deploying flowers cnn from gs://qwiklabs-gcp-fbe436fd47a7ee13/flowers/trained_cnn/export/exporter/1554345358/ ... this will take a few minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created ml engine model [projects/qwiklabs-gcp-fbe436fd47a7ee13/models/flowers].\n",
      "Creating version (this might take a few minutes)......\n",
      "..............................................................................................................................................................................................................................................................................................done.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "MODEL_NAME=\"flowers\"\n",
    "MODEL_VERSION=${MODEL_TYPE}\n",
    "MODEL_LOCATION=$(gsutil ls gs://${BUCKET}/flowers/trained_${MODEL_TYPE}/export/exporter | tail -1)\n",
    "echo \"Deleting and deploying $MODEL_NAME $MODEL_VERSION from $MODEL_LOCATION ... this will take a few minutes\"\n",
    "#gcloud ml-engine versions delete --quiet ${MODEL_VERSION} --model ${MODEL_NAME}\n",
    "#gcloud ml-engine models delete ${MODEL_NAME}\n",
    "gcloud ml-engine models create ${MODEL_NAME} --regions $REGION\n",
    "gcloud ml-engine versions create ${MODEL_VERSION} --model ${MODEL_NAME} --origin ${MODEL_LOCATION} --runtime-version=$TFVERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict with the model, let's take one of the example images that is available on Google Cloud Storage <img src=\"http://storage.googleapis.com/cloud-ml-data/img/flower_photos/sunflowers/1022552002_2b93faf9e7_n.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The online prediction service expects images to be base64 encoded as described [here](https://cloud.google.com/ml-engine/docs/tensorflow/online-predict#binary_data_in_prediction_input)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying gs://cloud-ml-data/img/flower_photos/sunflowers/1022552002_2b93faf9e7_n.jpg...\n",
      "/ [0 files][    0.0 B/ 41.7 KiB]                                                \r",
      "/ [1 files][ 41.7 KiB/ 41.7 KiB]                                                \r\n",
      "Operation completed over 1 objects/41.7 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "IMAGE_URL=gs://cloud-ml-data/img/flower_photos/sunflowers/1022552002_2b93faf9e7_n.jpg\n",
    "\n",
    "# Copy the image to local disk.\n",
    "gsutil cp $IMAGE_URL flower.jpg\n",
    "\n",
    "# Base64 encode and create request message in json format.\n",
    "python -c 'import base64, sys, json; img = base64.b64encode(open(\"flower.jpg\", \"rb\").read()).decode(); print(json.dumps({\"image_bytes\":{\"b64\": img}}))' &> request.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send it to the prediction service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASS       CLASSID  PROBABILITIES\n",
      "sunflowers  3        [9.43810027820291e-06, 0.00011202607856830582, 9.946910722646862e-06, 0.9997740387916565, 9.453093662159517e-05]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud ml-engine predict \\\n",
    "  --model=flowers \\\n",
    "  --version=${MODEL_TYPE} \\\n",
    "  --json-instances=./request.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "# Copyright 2017 Google Inc. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "</pre>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
